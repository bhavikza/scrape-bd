name: Bd Scraper

on:
  schedule:
    # Runs every 10 minutes from minute 0 through 59 past every hour from 8 through 22 (10pm) UTC.
    # Note: GitHub Actions uses UTC. If you are in BST/GMT (London), this is roughly accurate but checks 
    # daylight savings if precision is required.
    - cron: '*/10 8-22 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Important: allows the action to commit data back to the repo

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run scraper
        env:
          # We map secrets from the repository settings to environment variables
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          DB_NAME: ${{ secrets.DB_NAME }}
          BASE_URL: ${{ secrets.BASE_URL }}
        run: python bd_extract.py

      - name: Commit and push database changes
        # Only invoke if the db file changed
        run: |
          git config user.name "Scraper Bot"
          git config user.email "actions@users.noreply.github.com"
          git add betdaq_data.db
          # 'git diff --staged --quiet' returns code 1 if there are changes, 0 if clean
          # We use "|| exit 0" to suppress error if nothing to commit
          timestamp=$(date -u)
          git commit -m "Data update: ${timestamp}" || exit 0
          git push
